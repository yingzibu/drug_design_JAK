{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/drug_design_JAK/blob/main/VAE/VAE_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p3HNe3MnHsYl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Reference: https://github.com/wohlert/semi-supervised-pytorch/tree/master\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from itertools import repeat\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VRmK1OtkIbLh"
      },
      "outputs": [],
      "source": [
        "def enumerate_discrete(x, y_dim):\n",
        "    def batch(batch_size, label):\n",
        "        labels = (torch.ones(batch_size, 1) * label).type(torch.LongTensor)\n",
        "        y = torch.zeros((batch_size, y_dim))\n",
        "        y.scatter_(1, labels, 1)\n",
        "        return y.type(torch.LongTensor)\n",
        "    batch_size = x.size(0)\n",
        "    generated = torch.cat([batch(batch_size, i) for i in range(y_dim)])\n",
        "    if x.is_cuda: generated = generated.cuda()\n",
        "    return Variable(generated.float())\n",
        "\n",
        "def onehot(k):\n",
        "    \"\"\"\n",
        "    Converts a number to its torch.Size([k])\n",
        "    one-hot representation vector\n",
        "    :param k: (int) length of vector\n",
        "    : return onehot function\n",
        "    \"\"\"\n",
        "    def encode(label):\n",
        "        y = torch.zeros(k)\n",
        "        if label < k: y[label] = 1\n",
        "        return y\n",
        "    return encode # torch.Size([k])\n",
        "\n",
        "def log_sum_exp(tensor, dim=-1, sum_op=torch.sum):\n",
        "    \"\"\"\n",
        "    :param tensor: Tensor to compute LogSumExp (LSE) over\n",
        "                    as approximation for the sum in a log domain\n",
        "    :param dim: dimension to perform opertation over\n",
        "    :param sum_op: reductive operation to be applied: torch.sum or torch.mean\n",
        "    :return LSE\n",
        "    \"\"\"\n",
        "    max, argmax = torch.max(tensor, dim=dim, keepdim=True)\n",
        "    LSE = torch.log(sum_op(torch.exp(tensor-max), dim=dim,\n",
        "                           keepdim=True) + 1e-8) + max\n",
        "    return LSE\n",
        "\n",
        "def log_gaussian(x, mu, logvar):\n",
        "    \":return log N(x|mu, var)\"\n",
        "    log_pdf = -0.5 * math.log(2*math.pi) - logvar / 2 - \\\n",
        "                (x - mu) **2 / (2 * torch.exp(logvar))\n",
        "    return torch.sum(log_pdf, dim=-1)\n",
        "\n",
        "def log_standard_gaussian(x):\n",
        "    mu = torch.zeros(x.shape)\n",
        "    logvar = torch.log(torch.ones_like(x)) # donot forget log!\n",
        "    return log_gaussian(x, mu, logvar)\n",
        "\n",
        "def log_standard_categorical(p):\n",
        "    \"\"\"\n",
        "    Returns H(p, u), u is a standard (uniform) categorical distribution\n",
        "    \"\"\"\n",
        "    prior = F.softmax(torch.ones_like(p))\n",
        "    prior.requires_grad = False\n",
        "    cross_entropy = - torch.sum(p*torch.log(prior+ 1e-8), dim=1)\n",
        "    return cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4WPtatNdJIhA"
      },
      "outputs": [],
      "source": [
        "class IWS(object):\n",
        "    \"\"\"\n",
        "    Importance weighted sampler (Burda 2015) to be used in conjunction with SVI\n",
        "    \"\"\"\n",
        "    def __init__(self, mc=1, iw=1):\n",
        "        \"\"\"\n",
        "        :param mc: number of Monte Carlo samples\n",
        "        :param iw: number of Importance Weighted samples\n",
        "        \"\"\"\n",
        "        self.mc = mc\n",
        "        self.iw = iw\n",
        "\n",
        "    def resample(self, x): return x.repeat(self.mc * self.iw, 1)\n",
        "\n",
        "    def __call__(self, elbo):\n",
        "        elbo = elbo.view(self.mc, self.iw, -1)\n",
        "        elbo = torch.mean(log_sum_exp(elbo, dim=1, sum_op=torch.mean), dim=0)\n",
        "        return elbo.view(-1)\n",
        "\n",
        "class SVI(nn.Module):\n",
        "    \"\"\"Stochastic variational inference (SVI)\"\"\"\n",
        "    base_sampler = IWS(mc=1, iw=1)\n",
        "    def __init__(self, model, likelihood=F.binary_cross_entropy,\n",
        "                 beta=repeat(1), sampler=base_sampler):\n",
        "        \"\"\"\n",
        "        Initializes a new SVI optimizer for semi-supervised learning\n",
        "        :param model: semi-supervised model to evaluate\n",
        "        :param likelihood: p(x|y, z) for example BCE or MSE\n",
        "        :param sampler: sampler for x and y, e.g. for Monte Carlo\n",
        "        :param beta: warm-up/scaling of KL-term\n",
        "        \"\"\"\n",
        "        super(SVI, self).__init__()\n",
        "        self.model = model\n",
        "        self.likelihood = likelihood\n",
        "        self.beta = beta\n",
        "        self.sampler = sampler\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        is_labelled = False if y is None else True\n",
        "        xs, ys = (x, y)\n",
        "        if not is_labelled:\n",
        "            ys = enumerate_discrete(xs, self.model.y_dim) # why\n",
        "            xs = xs.repeat(self.model.y_dim, 1)\n",
        "        xs = self.sampler.resample(xs)\n",
        "        ys = self.sampler.resample(ys)\n",
        "        reconstruction = self.model(xs, ys) # x, y -> z, y -> x\n",
        "\n",
        "        # p(x|y, z)\n",
        "        likelihood = -self.likelihood(reconstruction, xs)\n",
        "\n",
        "        # p(y)\n",
        "        prior = -log_standard_categorical(ys)\n",
        "\n",
        "        # -L(x, y) = E_q_theta(z|x, y) [log p_theta(x|y, z) + log p(y)\n",
        "        #                               + log p(z) - log q_phi(z|x, y)]\n",
        "        #          = likelihood + prior - KL_divergence\n",
        "        elbo = likelihood + prior - next(self.beta) * self.model.kl_divergence\n",
        "        elbo = self.sampler(elbo)\n",
        "\n",
        "        if is_labelled: return torch.mean(elbo)\n",
        "\n",
        "        logits = self.model.classify(x)\n",
        "        elbo = elbo.view_as(logits.t()).t()\n",
        "\n",
        "        H = - torch.sum(torch.mul(logits, torch.log(logits+1e-8)), dim=-1)\n",
        "        L_minus = torch.sum(torch.mul(logits, elbo), dim=-1)\n",
        "\n",
        "        return torch.mean(H + L_minus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DZmo3aZuJN1c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/wohlert/semi-supervised-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLVTpbZ2Jjj_",
        "outputId": "e18fe82b-23ba-4dfc-96ec-32767fc1ff66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/semi-supervised-pytorch/semi-supervised\n"
          ]
        }
      ],
      "source": [
        "cd /content/semi-supervised-pytorch/semi-supervised/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cok7tuqhJtiw"
      },
      "outputs": [],
      "source": [
        "from models import StackedDeepGenerativeModel, DeepGenerativeModel\n",
        "from models import VariationalAutoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SWPbJUYxKq0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb90a394-5293-4619-8e73-20bb6618230d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VariationalAutoencoder(\n",
              "  (encoder): Encoder(\n",
              "    (hidden): ModuleList(\n",
              "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
              "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "    )\n",
              "    (sample): GaussianSample(\n",
              "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
              "      (log_var): Linear(in_features=128, out_features=32, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (hidden): ModuleList(\n",
              "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
              "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
              "    )\n",
              "    (reconstruction): Linear(in_features=256, out_features=784, bias=True)\n",
              "    (output_activation): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y_dim = 10\n",
        "z_dim = 32\n",
        "h_dim = [256, 128]\n",
        "x_dim = 784\n",
        "model_VAE = VariationalAutoencoder([x_dim, z_dim, h_dim])\n",
        "model_VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YqDz-KHXKvik"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oiBWEGKMLS2f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "from urllib import request\n",
        "from torch.utils.data import Dataset\n",
        "sys.path.append(\"../semi-supervised\")\n",
        "n_labels = 10\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "class SpriteDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch wrapper for the dSprites dataset by\n",
        "    Matthey et al. 2017. The dataset provides a 2D scene\n",
        "    with a sprite under different transformations:\n",
        "    * color\n",
        "    * shape\n",
        "    * scale\n",
        "    * orientation\n",
        "    * x-position\n",
        "    * y-position\n",
        "    \"\"\"\n",
        "    def __init__(self, transform=None):\n",
        "        self.transform = transform\n",
        "        url = \"https://github.com/deepmind/dsprites-dataset/raw/master/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"\n",
        "\n",
        "        try:\n",
        "            self.dset = np.load(\"./dsprites.npz\", encoding=\"bytes\")[\"imgs\"]\n",
        "        except FileNotFoundError:\n",
        "            request.urlretrieve(url, \"./dsprites.npz\")\n",
        "            self.dset = np.load(\"./dsprites.npz\", encoding=\"bytes\")[\"imgs\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dset[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "def get_mnist(location=\"./\", batch_size=64, labels_per_class=100):\n",
        "    from functools import reduce\n",
        "    from operator import __or__\n",
        "    from torch.utils.data.sampler import SubsetRandomSampler\n",
        "    from torchvision.datasets import MNIST\n",
        "    import torchvision.transforms as transforms\n",
        "    from utils import onehot\n",
        "\n",
        "    flatten_bernoulli = lambda x: transforms.ToTensor()(x).view(-1).bernoulli()\n",
        "\n",
        "    mnist_train = MNIST(location, train=True, download=True,\n",
        "                        transform=flatten_bernoulli, target_transform=onehot(n_labels))\n",
        "    mnist_valid = MNIST(location, train=False, download=True,\n",
        "                        transform=flatten_bernoulli, target_transform=onehot(n_labels))\n",
        "\n",
        "    def get_sampler(labels, n=None):\n",
        "        # Only choose digits in n_labels\n",
        "        (indices,) = np.where(reduce(__or__, [labels == i for i in np.arange(n_labels)]))\n",
        "\n",
        "        # Ensure uniform distribution of labels\n",
        "        np.random.shuffle(indices)\n",
        "        indices = np.hstack([list(filter(lambda idx: labels[idx] == i, indices))[:n] for i in range(n_labels)])\n",
        "\n",
        "        indices = torch.from_numpy(indices)\n",
        "        sampler = SubsetRandomSampler(indices)\n",
        "        return sampler\n",
        "\n",
        "    # Dataloaders for MNIST\n",
        "    labelled = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, num_workers=2, pin_memory=cuda,\n",
        "                                           sampler=get_sampler(mnist_train.train_labels.numpy(), labels_per_class))\n",
        "    unlabelled = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, num_workers=2, pin_memory=cuda,\n",
        "                                             sampler=get_sampler(mnist_train.train_labels.numpy()))\n",
        "    validation = torch.utils.data.DataLoader(mnist_valid, batch_size=batch_size, num_workers=2, pin_memory=cuda,\n",
        "                                             sampler=get_sampler(mnist_valid.test_labels.numpy()))\n",
        "\n",
        "    return labelled, unlabelled, validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA5oFysnLXvt"
      },
      "outputs": [],
      "source": [
        "l, u, v = get_mnist(location='./', batch_size=64, labels_per_class=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VCTJnm2Lcw1G"
      },
      "outputs": [],
      "source": [
        "_, train, val = get_mnist(location = './', batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uNKwBswSLoCv"
      },
      "outputs": [],
      "source": [
        "def binary_cross_entropy(r, x):\n",
        "    return -torch.sum(x * torch.log(r+1e-8) + \\\n",
        "           (1-x) * torch.log(1-r + 1e-8), dim=-1)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_VAE.parameters(),\n",
        "                             lr=3e-4, betas=(0.9, 0.999))\n",
        "# alpha = 0.1 * len(u)/len(l)\n",
        "from itertools import cycle\n",
        "# from inference import SVI, IWS\n",
        "sampler = IWS(mc=1, iw=1)\n",
        "if cuda: model_VAE = model_VAE.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "GLvKyWXolV1U"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "TsJC_hvIbS3Y",
        "outputId": "007a3f43-dc64-4938-e296-756ce145c229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 0: 100%|██████████| 938/938 [00:39<00:00, 23.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\tL: 127.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid \tL: 127.21\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e03e9b53-12f5-4d2f-8756-1cdf9ff16614\", \"VAE_digits_pretrain_0.pt\", 1928539)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1: 100%|██████████| 938/938 [00:39<00:00, 23.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1\tL: 127.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2: 100%|██████████| 938/938 [00:40<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2\tL: 127.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3: 100%|██████████| 938/938 [00:41<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3\tL: 127.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4: 100%|██████████| 938/938 [00:39<00:00, 23.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4\tL: 127.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5: 100%|██████████| 938/938 [00:39<00:00, 23.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5\tL: 127.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid \tL: 126.59\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5b5c36d-284e-48c6-9893-b5750d005645\", \"VAE_digits_pretrain_5.pt\", 1928539)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6: 100%|██████████| 938/938 [00:39<00:00, 23.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6\tL: 127.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7:  81%|████████▏ | 763/938 [00:32<00:07, 24.73it/s]"
          ]
        }
      ],
      "source": [
        "for epoch in range(50):\n",
        "    model_VAE.train()\n",
        "    total_loss = 0\n",
        "    for (u, _) in tqdm(train, desc=f\"epoch {epoch}\"):\n",
        "        u = Variable(u)\n",
        "\n",
        "        if cuda: u = u.cuda(device=0)\n",
        "\n",
        "        reconstruction = model_VAE(u)\n",
        "\n",
        "        likelihood = -binary_cross_entropy(reconstruction, u)\n",
        "        elbo = likelihood - model_VAE.kl_divergence\n",
        "\n",
        "        L = -torch.mean(elbo)\n",
        "\n",
        "        L.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += L.data.item()\n",
        "\n",
        "    m = len(train)\n",
        "    print(f\"Epoch {epoch}\\tL: {total_loss/m:.2f}\")\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        model_VAE.eval()\n",
        "        val_loss = 0\n",
        "        for (u, _) in val:\n",
        "            u = Variable(u)\n",
        "            if cuda: u = u.cuda(device=0)\n",
        "            recon = model_VAE(u)\n",
        "            l = -binary_cross_entropy(recon, u)\n",
        "            elbo = l - model_VAE.kl_divergence\n",
        "            L = -torch.mean(elbo)\n",
        "            val_loss += L.data.item()\n",
        "        print(f\"Valid \\tL: {val_loss/len(val):.2f}\")\n",
        "\n",
        "        torch.save(model_VAE.state_dict(), 'VAE_digits_pretrain_' + str(epoch) + \".pt\")\n",
        "        files.download('VAE_digits_pretrain_' + str(epoch) + \".pt\")\n",
        "# model.load_state_dict(torch.load('VAE_digits_pretrain_' + str(epoch) + \".pt\",\n",
        "#                                     map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBnLCDyalSdp",
        "outputId": "256005fc-b302-4c9f-de79-154af70a3ce1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZB-myHkWm1T"
      },
      "outputs": [],
      "source": [
        "# kwargs = {'num_workers':1, 'pin_memory': True}\n",
        "# batch_size = 126\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                    transform=transforms.ToTensor()),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, download=True,\n",
        "#                    transform=transforms.ToTensor()),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# def loss_function(recon_x, x, mu, logvar):\n",
        "#     BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "#     return BCE + KLD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ghcFk-gVMV",
        "outputId": "e7dcfc5b-4556-4c37-9d91-8011cd392caf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x789fac0c02e0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WLQFLQSAXwf2"
      },
      "outputs": [],
      "source": [
        "# device = 'cuda'\n",
        "# for epoch in range(10):\n",
        "#     model_VAE.train()\n",
        "#     total_loss = 0\n",
        "#     for i, (data, _) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "#         # optimizer.zero_grad()\n",
        "#         if cuda: data = data.to(device)\n",
        "#         recon_batch = model_VAE(data.view(-1, 784))\n",
        "\n",
        "#         BCE_loss = F.binary_cross_entropy(recon_batch, data.view(-1, 784),\n",
        "#                                       reduction='sum')\n",
        "#         loss = BCE_loss + torch.mean(model_VAE.kl_divergence)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         total_loss += loss.data.item()\n",
        "#     if epoch % 1 == 0:\n",
        "#         model_VAE.eval()\n",
        "#         print('Epoch :{}'.format(epoch))\n",
        "#         print('[Train] \\t loss:{:.2f}'.format(total_loss/len(train_loader)))\n",
        "#         val_loss = 0\n",
        "#         for (data, _) in test_loader:\n",
        "#             if cuda: data = data.to(device)\n",
        "\n",
        "#             recon_batch = model_VAE(data.view(-1, 784))\n",
        "#             BCE_loss = F.binary_cross_entropy(recon_batch, data.view(-1, 784),\n",
        "#                                       reduction='sum')\n",
        "#             loss = BCE_loss + torch.mean(model_VAE.kl_divergence)\n",
        "#             val_loss += loss.data.item()\n",
        "#         print('[valid] \\t loss:{:.2f}'.format(loss / len(test_loader)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phky1bRuaXc3",
        "outputId": "75939c75-5529-4611-8fa2-e4303a6ed5f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(69300.1406, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BCE_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp4iuzkwMMGQ",
        "outputId": "fae8a8ec-b1ce-48d9-ab54-9da490cb9b01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-7.1520)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_gaussian(onehot(3)(2), torch.Tensor([1, 2, 3]), torch.Tensor([3, 2, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKpGAOc0NV6N"
      },
      "outputs": [],
      "source": [
        "def log_standard_gaussian_or(x):\n",
        "    \"\"\"\n",
        "    Evaluates the log pdf of a standard normal distribution at x.\n",
        "\n",
        "    :param x: point to evaluate\n",
        "    :return: log N(x|0,I)\n",
        "    \"\"\"\n",
        "    return torch.sum(-0.5 * math.log(2 * math.pi) - x ** 2 / 2, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6oip9QyN9Hx",
        "outputId": "dbb7530e-d77b-48ca-a091-cb90b21fcac3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_standard_gaussian(onehot(3)(2)) == log_standard_gaussian_or(onehot(3)(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "QQ7Q9blvOCdo",
        "outputId": "d7544895-3fb1-477f-e6e9-3ee408008470"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-59-9ca38cdb1315>:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  F.softmax(torch.ones_like(onehot(3)(2)).T, dim=1)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-9ca38cdb1315>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1844\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "F.softmax(torch.ones_like(onehot(3)(2)).T, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XG3HBeXOEcB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1HZOH0F6EtGRgu6HuakXz6HynGApL5r2I",
      "authorship_tag": "ABX9TyO8TJh/kjeu5dKUPBAjgk9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}