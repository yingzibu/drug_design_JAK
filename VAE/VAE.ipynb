{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWFCYdWXjNEmq7lyX7B8Hg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/drug_design_JAK/blob/main/VAE/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.distributions as td\n",
        "from torch.distributions import Categorical, Normal, Bernoulli\n"
      ],
      "metadata": {
        "id": "W2lCysm-jHkz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kampta/pytorch-distributions/blob/master/gaussian_vae.py"
      ],
      "metadata": {
        "id": "_XsDXAqknKa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "# if : device = torch.device('cuda')\n",
        "# else: device = torch.device('cpu')\n",
        "# print(device)"
      ],
      "metadata": {
        "id": "wWBejuFcjwpU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "xbNGu7KjoYPd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "7yAFOgbCoI75"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_FGIt9Bvo9sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\"\n",
        "batch_size = 128\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "\n",
        "# print(device)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "metadata": {
        "id": "v-yhIttCjjdc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "knVDX9iUnZhj",
        "outputId": "63677b9e-2596-4f31-f99a-3525655adf97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "    def encode(self, x):\n",
        "        # print('x.shape: ', x.shape) # x.shape:  torch.Size([128, 784])\n",
        "\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1) # mu, logvar\n",
        "\n",
        "    def decode(self, z):\n",
        "        # print('z shape: ', z.shape) # [20, 784]\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "        # return self.fc4(h3)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = logvar.exp().pow(0.5)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x.shape in forward : ', x.shape)\n",
        "        # x.shape in forward :  torch.Size([128, 1, 28, 28])\n",
        "\n",
        "        # print('after view x.view(-1, 784): ', x.view(-1, 784).shape)\n",
        "        # after view x.view(-1, 784):  torch.Size([128, 784])\n",
        "\n",
        "        mu, logvar = self.encode(x.view(-1, 784))\n",
        "        # std = logvar.exp().pow(0.5)\n",
        "        # eps = torch.randn_like(std)\n",
        "        # q_z = td.normal.Normal(mu, std)\n",
        "        # z = q_z.rsample()\n",
        "\n",
        "        # return self.decode(z), q_z\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "S174o6s1j95T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.cuda(), x.view(-1, 784).cuda(), reduction='sum')\n",
        "    # p_z = td.normal.Normal(torch.zeros_like(q_z.loc),\n",
        "    #                        torch.ones_like(q_z.scale))\n",
        "    # KLD = td.kl_divergence(q_z, p_z).sum()\n",
        "    KLD  = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n"
      ],
      "metadata": {
        "id": "VAiQzofwk--b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch, log_interval=100):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        # print('recon_batch.size: ', recon_batch.shape)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))"
      ],
      "metadata": {
        "id": "cDhjwfojlaUU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train(1000)"
      ],
      "metadata": {
        "id": "djV7TyTAqZ0O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            # recon_batch, q_z = model(data)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "        # print('recon_batch.size: ', recon_batch.shape)\n",
        "            # loss = loss_function(recon_batch, data, mu, logvar)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                       recon_batch.view(-1, 1, 28, 28)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                           'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "metadata": {
        "id": "GKj-PzMEl3KU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_path(path):\n",
        "    # Check whether the specified path exists or not\n",
        "    isExist = os.path.exists(path)\n",
        "    #printing if the path exists or not\n",
        "    print(path, ' folder is in directory: ', isExist)\n",
        "    if not isExist:\n",
        "    # Create a new directory because it does not exist\n",
        "        os.makedirs(path)\n",
        "        print(path, \" is created!\")\n",
        "create_path('results/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk29zjlxto4z",
        "outputId": "4e7ec247-e527-4c35-adcb-e69ed45ab1c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results/  folder is in directory:  False\n",
            "results/  is created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 10000\n",
        "for epoch in range(1, epoch + 1):\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(64, 20).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            save_image(sample.view(64, 1, 28, 28),\n",
        "                       'results/sample_' + str(epoch) + '.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfSiRMtamGp5",
        "outputId": "50aaf224-8b62-4ca4-ff30-d67af2716c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 114.546173\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 112.012741\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 114.769058\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 111.623871\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 106.539276\n",
            "====> Epoch: 1 Average loss: 111.5362\n",
            "====> Test set loss: 109.6628\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 109.747360\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 111.914474\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 108.009048\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 114.255783\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 110.236679\n",
            "====> Epoch: 2 Average loss: 109.7891\n",
            "====> Test set loss: 108.2379\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 106.076378\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 111.225189\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 106.969620\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 106.944221\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 111.025528\n",
            "====> Epoch: 3 Average loss: 108.6332\n",
            "====> Test set loss: 107.6086\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 110.026627\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 107.902740\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 107.763245\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 104.216080\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 110.616333\n",
            "====> Epoch: 4 Average loss: 107.7365\n",
            "====> Test set loss: 107.2493\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 107.651566\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 105.233559\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 105.531731\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 107.861092\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 106.672760\n",
            "====> Epoch: 5 Average loss: 107.1640\n",
            "====> Test set loss: 106.3840\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 109.004837\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 105.180939\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 109.369087\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 105.222496\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 103.347801\n",
            "====> Epoch: 6 Average loss: 106.5978\n",
            "====> Test set loss: 105.8692\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 106.834343\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 106.188065\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 101.850357\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 98.603729\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 108.828880\n",
            "====> Epoch: 7 Average loss: 106.2497\n",
            "====> Test set loss: 105.6901\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 103.852715\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 104.007797\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 105.545059\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 108.303467\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 104.294250\n",
            "====> Epoch: 8 Average loss: 105.8086\n",
            "====> Test set loss: 105.3774\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 103.269447\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 105.546272\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 108.851021\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 104.650238\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 107.492111\n",
            "====> Epoch: 9 Average loss: 105.5380\n",
            "====> Test set loss: 105.0633\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 104.400299\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 104.006149\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 106.003891\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 105.023987\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 107.700768\n",
            "====> Epoch: 10 Average loss: 105.2821\n",
            "====> Test set loss: 104.9243\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 105.351883\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 106.085434\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 105.457672\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 107.293083\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 104.637505\n",
            "====> Epoch: 11 Average loss: 105.0265\n",
            "====> Test set loss: 104.6767\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 105.163483\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 104.364677\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 105.392441\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 105.076019\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 101.643005\n",
            "====> Epoch: 12 Average loss: 104.8175\n",
            "====> Test set loss: 104.4889\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 106.783318\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 103.149475\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 101.262512\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 106.034859\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 106.051895\n",
            "====> Epoch: 13 Average loss: 104.6429\n",
            "====> Test set loss: 104.4698\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 104.429504\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 103.453316\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 105.408188\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 100.200989\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 102.231079\n",
            "====> Epoch: 14 Average loss: 104.4288\n",
            "====> Test set loss: 104.0110\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 104.252129\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 100.261589\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 103.782974\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 101.435577\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 99.471924\n",
            "====> Epoch: 15 Average loss: 104.2953\n",
            "====> Test set loss: 104.0995\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 100.710182\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 104.237167\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 103.736618\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 98.325714\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 101.643242\n",
            "====> Epoch: 16 Average loss: 104.1265\n",
            "====> Test set loss: 103.9617\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 105.546135\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 103.987373\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 100.109772\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 104.122047\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 105.309616\n",
            "====> Epoch: 17 Average loss: 104.0033\n",
            "====> Test set loss: 103.8522\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 104.807129\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 108.419472\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 104.719284\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 100.698822\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 105.678741\n",
            "====> Epoch: 18 Average loss: 103.8857\n",
            "====> Test set loss: 103.7503\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 104.901527\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 104.137207\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 103.311203\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 102.737244\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 107.757561\n",
            "====> Epoch: 19 Average loss: 103.7444\n",
            "====> Test set loss: 103.7252\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 107.200134\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 99.225433\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 101.680634\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 105.409752\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 101.162155\n",
            "====> Epoch: 20 Average loss: 103.5776\n",
            "====> Test set loss: 103.5429\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 104.169464\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 105.358604\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 101.223206\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 102.136551\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 101.606598\n",
            "====> Epoch: 21 Average loss: 103.5192\n",
            "====> Test set loss: 103.3295\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 103.994629\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 103.781113\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 102.927094\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 101.790466\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 108.427284\n",
            "====> Epoch: 22 Average loss: 103.4019\n",
            "====> Test set loss: 103.1969\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 106.787796\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 107.746277\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 101.530487\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 104.579727\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 103.245567\n",
            "====> Epoch: 23 Average loss: 103.3177\n",
            "====> Test set loss: 103.2655\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 102.343651\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 103.197144\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 102.905243\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 105.624397\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 104.966316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6_49_bBIsa-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "ax = plt.axes(projection='3d')\n",
        "\n",
        "# Data for a three-dimensional line\n",
        "zline = np.linspace(0, 15, 1000)\n",
        "xline = np.sin(zline)\n",
        "yline = np.cos(zline)\n",
        "ax.plot3D(xline, yline, zline, 'gray')\n",
        "\n",
        "# Data for three-dimensional scattered points\n",
        "zdata = 15 * np.random.random(100)\n",
        "xdata = np.sin(zdata) + 0.1 * np.random.randn(100)\n",
        "ydata = np.cos(zdata) + 0.1 * np.random.randn(100)\n",
        "ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='Greens');\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, y):\n",
        "    return np.sin(np.sqrt(x ** 2 + y ** 2))\n",
        "def f(x, y):\n",
        "    return -1 * np.sqrt(x ** 2 + y ** 2)\n",
        "\n",
        "\n",
        "x = np.linspace(-6, 6, 30)\n",
        "y = np.linspace(-6, 6, 30)\n",
        "\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = f(X, Y)\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z');\n",
        "ax.scatter([0, 1], [1, 1], [2, 1])"
      ],
      "metadata": {
        "id": "ZS9VTOcDI92k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical, Normal, Bernoulli\n",
        "\n",
        "# Gym\n",
        "# import gym\n",
        "# import gym_pygame\n",
        "\n",
        "# Hugging Face Hub\n",
        "# from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "import imageio"
      ],
      "metadata": {
        "id": "Bs_n1u7kJaz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self, s_size, a_size, h_size):\n",
        "        super(Policy, self).__init__()\n",
        "        self.s_size = s_size\n",
        "        self.fc1 = nn.Linear(s_size, h_size)\n",
        "        self.fc2 = nn.Linear(h_size, h_size*2)\n",
        "        self.fc3_1 = nn.Linear(h_size*2, a_size)\n",
        "        self.fc3_2 = nn.Linear(h_size*2, a_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.to(device).astype(np.float32)\n",
        "        # x = x.long().to(device)\n",
        "        # print('x: ', x.shape)\n",
        "        if x.shape == (1, self.s_size):\n",
        "            x = x.float().to(device)\n",
        "        else: x = x.float().unsqueeze(0).to(device)\n",
        "\n",
        "        # print(x)\n",
        "        # print(x.shape)\n",
        "        # print(type(x))\n",
        "        x = x.to(device)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        mu = self.fc3_1(x)\n",
        "        logvar = self.fc3_2(x)\n",
        "        # print(type(mu), type(logvar))\n",
        "        return mu, logvar\n",
        "        # return F.softmax(x, dim=1)\n",
        "\n",
        "    # def act_categorical(self, state):\n",
        "    #     state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "    #     probs = self.forward(state).cpu()\n",
        "    #     m = Categorical(probs)\n",
        "    #     action = m.sample()\n",
        "    #     return action.item(), m.log_prob(action)\n",
        "\n",
        "    def act(self, state, eta=1e-2):\n",
        "        # print(state)\n",
        "        if isinstance(state, torch.Tensor):\n",
        "            state = state.to(device)\n",
        "        else:\n",
        "            state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        # state = torch.from_numpy(state).float().to(device)\n",
        "        # print(state, type(state), state.shape)\n",
        "        # print(state.device)\n",
        "        mu, logvar = self.forward(state)\n",
        "        # mu = mu.cpu()\n",
        "        # logvar = logvar.cpu()\n",
        "        std = logvar.exp().pow(0.5)\n",
        "        p = Normal(mu, std)\n",
        "        # p_z = td.normal.Normal(torch.zeros_like(q_z.loc), torch.ones_like(q_z.scale))\n",
        "        action = p.rsample()\n",
        "        log_action = p.log_prob(action)\n",
        "        # m = Normal(*probs)\n",
        "        # action = m.rsample()\n",
        "        # action = mu + eta * logvar\n",
        "        return action, log_action"
      ],
      "metadata": {
        "id": "noc-9CJDJCJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.distributions as td\n",
        "# def forward(self, x):\n",
        "#         mu, logvar = self.encode(x.view(-1, 784))\n",
        "\n",
        "#         std = logvar.exp().pow(0.5)         # logvar to std\n",
        "#         q_z = td.normal.Normal(mu, std)     # create a torch distribution\n",
        "#         z = q_z.rsample()                   # sample with reparameterization\n",
        "\n",
        "#         return self.decode(z), q_z"
      ],
      "metadata": {
        "id": "LQihtSG1Wr0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# std = logvar.exp().pow(0.5) # logvar to std\n",
        "# q_z = td.normal.Normal(mu, std)\n"
      ],
      "metadata": {
        "id": "2o1qqUdcWdg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "id": "nTBwSyyJLPOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reinforce(policy, optimizer, env, n_training_episodes=1000,\n",
        "              max_t=100, gamma=1.0, print_every=10):\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "    for i in range(1, n_training_episodes+1):\n",
        "        saved_log_probs = []\n",
        "        rewards = []\n",
        "        state = env.reset()\n",
        "        # print('state here', state)\n",
        "        for t in range(max_t):  # one episode\n",
        "            action, log_prob = policy.act(state)\n",
        "            saved_log_probs.append(log_prob)\n",
        "            state, reward, done = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            if done:\n",
        "                break\n",
        "        scores_deque.append(sum(rewards))\n",
        "        scores.append(sum(rewards)) # for one episode, total R\n",
        "\n",
        "        returns = deque(maxlen=max_t)\n",
        "        n_steps = len(rewards)\n",
        "        for t in range(n_steps)[::-1]:\n",
        "            disc_return_t = (returns[0] if len(returns)>0 else 0)\n",
        "            returns.appendleft(gamma*disc_return_t + rewards[t])\n",
        "        eps = np.finfo(np.float32).eps.item()\n",
        "        ## eps is the smallest representable float, which is\n",
        "        # added to the standard deviation of the returns to avoid numerical instabilities\n",
        "        returns = torch.tensor(returns)\n",
        "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
        "\n",
        "        policy_loss = []\n",
        "        for log_prob, disc_return in zip(saved_log_probs, returns):\n",
        "            policy_loss.append(-log_prob * disc_return)\n",
        "\n",
        "        policy_loss = torch.cat(policy_loss).sum()\n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % print_every == 0:\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(\n",
        "                i, np.mean(scores_deque)))\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "nWIyEravOBtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_s = s.unsqueeze(0)\n",
        "new_s.shape == (1, 1, 2)"
      ],
      "metadata": {
        "id": "vHNfXzhXglFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class env:\n",
        "    def __init__(self, f):\n",
        "        # self.observation_space.n = 2\n",
        "        # self.action_space.n = 2\n",
        "        # state =\n",
        "        self.state = torch.from_numpy(np.random.rand(2))\n",
        "        self.f = f\n",
        "        self.reward = 0\n",
        "        self.done = False\n",
        "        # self.info = None\n",
        "\n",
        "    def reset(self):\n",
        "        # self.state = np.random.rand(2)\n",
        "        self.state = torch.from_numpy(np.random.rand(2))\n",
        "        self.done = False\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, step=1e-3, error=1e-6):\n",
        "        done = False\n",
        "        # print('state:' , self.state, type(self.state), self.state.shape)\n",
        "        # print('action: ', action.shape, type(action))\n",
        "        # print('self.state', self.state, type(self.state), isinstance(self.state, torch.Tensor))\n",
        "        if isinstance(self.state, torch.Tensor):\n",
        "            current_state = self.state\n",
        "        else: # numpy\n",
        "            current_state = torch.from_numpy(self.state).double().unsqueeze(0).to(device)\n",
        "\n",
        "        action = action.to(device)\n",
        "        current_state = current_state.to(device)\n",
        "        # print(action*step)\n",
        "        state = current_state + action*step\n",
        "        # print(state, type(state))\n",
        "        reward = 0\n",
        "        # try:\n",
        "        #     reward = self.f(state[0], state[1])\n",
        "        # except: reward = self.f(state[0][0], state[1][0])\n",
        "        try:\n",
        "            reward = self.f(state.detach().cpu().numpy()[0][0],\n",
        "                            state.detach().cpu().numpy()[0][1])\n",
        "        except:\n",
        "            print('cannot calculate reward', state)\n",
        "        # print(state)\n",
        "        # print(abs(-1 * sum(state - current_state)[0]))\n",
        "        if abs(-1 * sum(state - current_state)[0]) < error:\n",
        "            done = True\n",
        "        self.done = done\n",
        "        self.state = state\n",
        "        self.reward = reward\n",
        "        return state, reward, done\n"
      ],
      "metadata": {
        "id": "2dUgB5egQYqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# env_1 = env(f)\n",
        "\n",
        "# a = torch.from_numpy(np.random.rand(2)).float().unsqueeze(0).to(device)\n",
        "# s, r, d = env_1.step(a)\n",
        "# r\n",
        "# # s.items()"
      ],
      "metadata": {
        "id": "skfhKi6SZAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# state.detach().cpu().numpy()[0]"
      ],
      "metadata": {
        "id": "fftV9KyAa_74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# state = s\n",
        "# f(state.detach().cpu().numpy()[0][0], state.detach().cpu().numpy()[0][1])"
      ],
      "metadata": {
        "id": "TJcMg4tKZPNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# isinstance(s.detach().cpu().numpy()[0][1], 'float')"
      ],
      "metadata": {
        "id": "5hT3v-ZPaNIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_1 = env(f)\n",
        "#\n",
        "p = Policy(2, 2, 16).to(device)\n",
        "cartpole_optimizer = optim.Adam(p.parameters(),\n",
        "                                lr=1e-2)\n",
        "scores = reinforce(p, cartpole_optimizer, env_1)"
      ],
      "metadata": {
        "id": "TdOstgadOWJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "id": "18qWGfO2aLSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.forward(s)"
      ],
      "metadata": {
        "id": "TS9oVDK-OajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = env(f)\n",
        "for i in range(10):\n",
        "    s, r, _ = b.step(a)\n",
        "    fig = plt.figure()\n",
        "    ax = plt.axes(projection='3d')\n",
        "    # ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_zlabel('z');\n",
        "    ax.scatter(s[0], s[1], r)\n",
        "    assert r == f(s[0], s[1])\n"
      ],
      "metadata": {
        "id": "xmzx9tDbLulr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a + a * (1e-3)\n",
        "# a"
      ],
      "metadata": {
        "id": "rmi484NqJnj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aev-A4v8Jvzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}