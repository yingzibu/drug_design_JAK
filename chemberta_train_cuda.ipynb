{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "13zRZH57GuWi_bpIiFUgxpLz26JWBWK_Y",
      "authorship_tag": "ABX9TyMLBFgq39Sy8OO74Rb7GJgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/drug_design_JAK/blob/main/chemberta_train_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tAbmGGAlgdHx",
        "outputId": "c00b3709-6af1-4ad4-e15b-0b6af0536f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/chemberta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zwI87agOg4Vr",
        "outputId": "c81d13fa-3cd4-42ad-b7f6-d717367dbc38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/chemberta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers  --quiet\n",
        "!pip install pubchempy --quiet\n",
        "!pip install rdkit --quiet"
      ],
      "metadata": {
        "id": "TXxNwq1NhGJY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, roc_auc_score"
      ],
      "metadata": {
        "id": "rp_YDiL7hCBG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MPNN   https://arxiv.org/pdf/1704.01212v2.pdf   \n",
        "\n",
        "chemberta-2 https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Transfer_Learning_With_ChemBERTa_Transformers.ipynb\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rbeyYXazqZZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from help_function import *\n",
        "from const import *\n",
        "from chembertforclassification import *\n",
        "from bert_encoder import *\n",
        "\n",
        "class jak_dataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        super(jak_dataset, self).__init__()\n",
        "\n",
        "        self.len = len(dataframe)\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            sml = self.dataframe.Smiles[idx]\n",
        "        except:\n",
        "            sml = self.dataframe.SMILES[idx]\n",
        "\n",
        "        y = 1 if self.dataframe.Activity[idx] == 1 else 0\n",
        "\n",
        "        return sml, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "def data_load(df, params={'batch_size': 16, 'shuffle': True,\n",
        "                          'drop_last': False, 'num_workers': 0}):\n",
        "    reset_df = df.reset_index(drop=True)\n",
        "    data = jak_dataset(reset_df)\n",
        "    loader = DataLoader(data, **params)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "OZUMaKEthR6g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'data_0.25uM/'\n",
        "if torch.cuda.is_available(): device='cuda'\n",
        "else: device='cpu'\n",
        "\n",
        "enzymes = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
        "model_path = 'model_epoch_20/'\n",
        "create_path(model_path) # if model_path exists, ignore, if not,create it"
      ],
      "metadata": {
        "id": "xddBpylUlXsx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for enzyme in enzymes:\n",
        "    print()\n",
        "    ind = enzymes.index(enzyme)\n",
        "    print(enzyme)\n",
        "    train_df = pd.read_csv(data_path + enzyme + '_train.csv')\n",
        "    valid_df = pd.read_csv(data_path + enzyme + '_valid.csv')\n",
        "    # print(train_df['Activity'].value_counts())\n",
        "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]),\n",
        "                   3: torch.tensor([2.0, 1.0]), 4: torch.tensor([2.0, 1.0])}\n",
        "    params = {'batch_size': 16, 'shuffle': True,\n",
        "              'drop_last': False, 'num_workers': 0}\n",
        "\n",
        "    train_loader = data_load(train_df, params)\n",
        "    valid_loader = data_load(valid_df, params)\n",
        "    epoches = 20\n",
        "    model_name = f'chembert_{enzyme}.pt'\n",
        "    file_exist = os.path.isfile(model_path + model_name)\n",
        "    print(f\"{model_path+model_name} existence: \", file_exist)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        model = chembertforclassification().cuda()\n",
        "    else: model = chembertforclassification()\n",
        "\n",
        "    if file_exist: # load model from predefined model_path\n",
        "        model.load_state_dict(torch.load(model_path+model_name,\n",
        "                                         map_location=torch.device(device)))\n",
        "    else: # trained model does not exist, need to train and save\n",
        "        optimizer = optim.AdamW(params=model.parameters(),\n",
        "                                lr=1e-5, weight_decay=1e-2)\n",
        "        loss_function = nn.CrossEntropyLoss(weight=weight_dict[ind+1].cuda())\n",
        "        model.train()\n",
        "        for epoch in range(epoches):\n",
        "            print(\"EPOCH -- {}\".format(epoch))\n",
        "            total_loss = 0\n",
        "            for idx, (x, y_true) in tqdm(enumerate(train_loader),\n",
        "                                         total=len(train_loader)):\n",
        "                # print(y_true)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(list(x))\n",
        "                loss = loss_function(output, y_true.cuda())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "        ###SAVE MODEL\n",
        "        torch.save(model.state_dict(), model_path + model_name)\n",
        "        print(f'model trained and saved at {model_path + model_name}')\n",
        "    model.eval()\n",
        "\n",
        "    accumulate_y_pred = []\n",
        "    accumulate_y_true = []\n",
        "    accumulate_y_prob = []\n",
        "    accumulate_x = []\n",
        "    for idx, (x, y_true) in tqdm(enumerate(valid_loader),\n",
        "                                 total=len(valid_loader)):\n",
        "        output = model(list(x))\n",
        "        _, y_pred = torch.max(output, 1)\n",
        "        accumulate_y_pred.extend(y_pred.tolist())\n",
        "        accumulate_y_true.extend(y_true.tolist())\n",
        "        accumulate_y_prob.extend(torch.softmax(output, 1)[:, 1].tolist())\n",
        "        accumulate_x.extend(list(x))\n",
        "    evaluate(accumulate_y_true, accumulate_y_pred, accumulate_y_prob)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "8HIz5lSil5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OCASD5yemQSw",
        "outputId": "599d8720-4f2b-4cb2-898d-483257633896"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chembert_TYK2.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_path('model/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1QflURjbnmVr",
        "outputId": "d7b999c9-72fa-42c0-98d1-b6418e2e8553"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model/  is created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = data_path + 'JAK1_valid.csv'\n",
        "file_exist = os.path.isfile(file_name)"
      ],
      "metadata": {
        "id": "6mLHma0sn3-M"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TamIKugOn-es",
        "outputId": "1b630556-77c8-48c1-941b-d04d4a992629"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "Fbpl93bqskSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QxtzQBMWvKBu",
        "outputId": "0fd1ac6c-f35a-4445-f21e-7c8c45614d06"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:00<00:00, 77.47it/s]\n"
          ]
        }
      ]
    }
  ]
}
